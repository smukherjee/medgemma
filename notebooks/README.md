# MedGemma Notebooks

*   [Quick start with Hugging Face](quick_start_with_hugging_face.ipynb) -
    Example of generating responses from medical text and images by running the
    model locally from Hugging Face.

*   [Quick start with Ollama](quick_start_with_ollama.ipynb) -
    Example of running MedGemma completely locally using Ollama for privacy-focused
    inference without requiring API tokens or internet connectivity.

*   [Quick start with Model Garden](quick_start_with_model_garden.ipynb) -
    Example of serving the model on
    [Vertex AI](https://cloud.google.com/vertex-ai/docs/predictions/overview)
    and using Vertex AI APIs to generate responses from medical text and images
    in online or batch workflows.

*   [Fine-tune with Hugging Face](fine_tune_with_hugging_face.ipynb) - Example
    of fine-tuning the model with LoRA using Hugging Face libraries.
